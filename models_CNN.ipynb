{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import train_datapath, test_datapath\n",
    "from utils import train_val_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_sliding_windows_batch(df, window_size, batch_size):\n",
    "    for start in range(0, len(df) - window_size + 1, batch_size):\n",
    "        end = min(start + batch_size, len(df) - window_size + 1)\n",
    "        batch_windows = [\n",
    "            df.iloc[i:i + window_size].values for i in range(start, end)\n",
    "        ]\n",
    "        yield np.array(batch_windows)\n",
    "        \n",
    "def create_h5py_file(df, window_size, batch_size, filename):\n",
    "    with h5py.File(filename, 'w') as h5f:\n",
    "        batch_index = 0\n",
    "        for batch in create_sliding_windows_batch(df, window_size, batch_size=batch_size):\n",
    "            train_images = batch.reshape(-1, window_size, df.shape[1])\n",
    "            h5f.create_dataset(f'batch_{batch_index}', data=train_images)\n",
    "            batch_index += 1\n",
    "\n",
    "train_df = pd.read_csv(train_datapath)\n",
    "test_df = pd.read_csv(test_datapath)\n",
    "\n",
    "\n",
    "window_size = 60\n",
    "batch_size = 1024\n",
    "\n",
    "# split the train_df into train and val\n",
    "X_train, y_train, X_val, y_val = train_val_split(train_df)\n",
    "X_train['target'] = y_train\n",
    "train_slice_df = X_train.copy()\n",
    "\n",
    "X_val['target'] = y_val\n",
    "val_slice_df = X_val.copy()\n",
    "\n",
    "train_file = 'data/train_images.h5'\n",
    "# if os.path.exists(train_file):\n",
    "create_h5py_file(train_slice_df, window_size, batch_size, train_file)\n",
    "\n",
    "val_file = 'data/validation_images.h5'\n",
    "# if os.path.exists(val_file):\n",
    "create_h5py_file(val_slice_df, window_size, batch_size, val_file)\n",
    "\n",
    "test_file = 'data/test_images.h5'\n",
    "# if os.path.exists(test_file):\n",
    "create_h5py_file(test_df, window_size, batch_size, test_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicCNN(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(BasicCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * (window_size // 2 // 2), 128)  # Adjust based on pooling layers\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * (window_size // 2 // 2))  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "def load_data_for_prediction_batch(h5_file, start_index, batch_size, window_size):\n",
    "    with h5py.File(h5_file, 'r') as h5f:\n",
    "        inputs = h5f['inputs'][start_index:start_index + batch_size]  # Load a batch of windows\n",
    "    return inputs  # Shape will be (batch_size, window_size, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicCNN(\n",
      "  (conv1): Conv1d(11, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (fc1): Linear(in_features=960, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Unable to synchronously open object (object 'inputs' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m  \u001b[38;5;66;03m# Number of samples to predict at once\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m100\u001b[39m, batch_size):  \u001b[38;5;66;03m# Predicting for the first 100 samples\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     input_batch \u001b[38;5;241m=\u001b[39m \u001b[43mload_data_for_prediction_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     predictions_batch \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(input_batch)\n\u001b[0;32m     19\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mextend(predictions_batch\u001b[38;5;241m.\u001b[39mflatten())\n",
      "Cell \u001b[1;32mIn[4], line 26\u001b[0m, in \u001b[0;36mload_data_for_prediction_batch\u001b[1;34m(h5_file, start_index, batch_size, window_size)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data_for_prediction_batch\u001b[39m(h5_file, start_index, batch_size, window_size):\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(h5_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m h5f:\n\u001b[1;32m---> 26\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[start_index:start_index \u001b[38;5;241m+\u001b[39m batch_size]  \u001b[38;5;66;03m# Load a batch of windows\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inputs\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\h5py\\_hl\\group.py:357\u001b[0m, in \u001b[0;36mGroup.__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid HDF5 object reference\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m)):\n\u001b[1;32m--> 357\u001b[0m     oid \u001b[38;5;241m=\u001b[39m \u001b[43mh5o\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_e\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccessing a group is done with bytes or str, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    360\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(name)))\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\h5o.pyx:257\u001b[0m, in \u001b[0;36mh5py.h5o.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Unable to synchronously open object (object 'inputs' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "input_channels = len(train_df.columns)  # Number of features\n",
    "num_classes = 1  # Binary classification\n",
    "\n",
    "model = BasicCNN(input_channels=input_channels, num_classes=num_classes)\n",
    "print(model)\n",
    "with h5py.File('train_images.h5', 'r') as h5f:\n",
    "    for batch_name in h5f:\n",
    "        train_images = h5f[batch_name][:]\n",
    "        # Train model with this batch\n",
    "\n",
    "\n",
    "predictions = []\n",
    "batch_size = 32  # Number of samples to predict at once\n",
    "for i in range(0, 100, batch_size):  # Predicting for the first 100 samples\n",
    "    input_batch = load_data_for_prediction_batch(val_file, i, batch_size, window_size)\n",
    "    predictions_batch = model.predict(input_batch)\n",
    "    predictions.extend(predictions_batch.flatten())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "minutes = (end_time - start_time) // 60\n",
    "seconds = (end_time - start_time) % 60\n",
    "print(f'Time elapsed: {minutes:.0f}m {seconds:.1f}s')\n",
    "print('--------------------------------------')\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_val, predictions)\n",
    "print(f'Validation Accuracy: {accuracy:.5f}')\n",
    "\n",
    "# Calculate F1 macro score\n",
    "f1_macro = f1_score(y_val, predictions, average='macro')\n",
    "print(f'Validation F1 Macro Score: {f1_macro:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (589211355.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    y_pred_prob = treated_model.predict(X_val_seq)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = []\n",
    "batch_size = 32  # Number of samples to predict at once\n",
    "for i in range(0, 100, batch_size):  # Predicting for the first 100 samples\n",
    "    input_batch = load_data_for_prediction_batch(test_file, i, batch_size, window_size)\n",
    "    predictions_batch = model.predict(input_batch)\n",
    "    predictions.extend(predictions_batch.flatten())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
